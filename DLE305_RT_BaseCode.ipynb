{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing libraries",
   "id": "a54d8ceace5470a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:06.968379Z",
     "start_time": "2024-12-03T03:43:59.780840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run if not everything installed\n",
    "!pip install tensorflow     > null 2>&1\n",
    "!pip install seaborn        > null 2>&1\n",
    "!pip install numpy          > null 2>&1\n",
    "!pip install pillow         > null 2>&1\n",
    "!pip install opencv-python  > null 2>&1\n",
    "!pip install scikit-learn   > null 2>&1\n",
    "#!pip install torchvision    > null 2>&1"
   ],
   "id": "18ac763866e90644",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:12.186564Z",
     "start_time": "2024-12-03T03:44:07.009878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#import tensorflow as tf\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, classification_report\n",
    "\n",
    "# from torchvision.transforms import (\n",
    "#     Compose,\n",
    "#     RandomHorizontalFlip,\n",
    "#     RandomRotation,\n",
    "# )"
   ],
   "id": "6d41e5de45384b4b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing",
   "id": "92dc9decc5d984fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:12.194187Z",
     "start_time": "2024-12-03T03:44:12.191549Z"
    }
   },
   "cell_type": "code",
   "source": "IMG_SIZE = (94, 125)",
   "id": "47c47e2d2b34d341",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:12.206989Z",
     "start_time": "2024-12-03T03:44:12.199812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing image transparency on pngs to prevent artefacts\n",
    "def remove_transparency (img):\n",
    "    if img.mode in ('RGBA', 'LA'):  # Check if the image has an alpha channel\n",
    "        bg = Image.new(\"RGB\", IMG_SIZE, \"black\")    # create solid black bg\n",
    "        bg.paste(img, mask=img.split()[3])      # Paste using alpha channel as a mask\n",
    "        return bg   # return resulting image\n",
    "    return img      # if no alpha channel return image unmodified"
   ],
   "id": "fae38ccbcef5d0c0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:12.213732Z",
     "start_time": "2024-12-03T03:44:12.210951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specifying final image size and resizing to that size\n",
    "def pixels_from_path(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    im = im.resize(IMG_SIZE)\n",
    "    im = remove_transparency(im)\n",
    "    im = im.convert(\"RGB\")\n",
    "    np_im = np.array(im)\n",
    "    # Returns 3D array of RGB values for image\n",
    "    return np_im"
   ],
   "id": "3c87fafffcd5fd2a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:12.220411Z",
     "start_time": "2024-12-03T03:44:12.217316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Making sets of training images\n",
    "def compile_set(file_path, size):\n",
    "    new_set = np.asarray([\n",
    "        pixels_from_path(animal)\n",
    "        for animal in glob.glob(file_path)[:size]\n",
    "        if pixels_from_path(animal) is not None\n",
    "    ])\n",
    "\n",
    "    return new_set"
   ],
   "id": "f8a96646274b75e3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:12.226896Z",
     "start_time": "2024-12-03T03:44:12.224001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Making sets of validation images\n",
    "def compile_valid_set(file_path, size):\n",
    "    new_set = np.asarray([\n",
    "        pixels_from_path(animal)\n",
    "        for animal in glob.glob(file_path)[-size:]\n",
    "        if pixels_from_path(animal) is not None\n",
    "    ])\n",
    "\n",
    "    return new_set"
   ],
   "id": "ee9bc67e7cdc1255",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:12.233351Z",
     "start_time": "2024-12-03T03:44:12.230683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Input relevant filepath before '/cat'\n",
    "cat_filepath = 'cat/*'\n",
    "dog_filepath = 'dog/*'\n",
    "tiger_filepath = 'tiger/*'\n",
    "lion_filepath = 'lion/*'"
   ],
   "id": "3d223d9db0129e42",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:33.405190Z",
     "start_time": "2024-12-03T03:44:12.240304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shape_counts = defaultdict(int)\n",
    "for i, cat in enumerate(glob.glob(cat_filepath)):\n",
    "    # Will print iteration no. if i+1 is a multiple of 500\n",
    "    if (i+1)%500==0:\n",
    "        print(i)\n",
    "    img_shape = pixels_from_path(cat).shape\n",
    "    shape_counts[str(img_shape)]= shape_counts[str(img_shape)]+ 1"
   ],
   "id": "420418a30617bb12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "999\n",
      "1499\n",
      "1999\n",
      "2499\n",
      "2999\n",
      "3499\n",
      "3999\n",
      "4499\n",
      "4999\n",
      "5499\n",
      "5999\n",
      "6499\n",
      "6999\n",
      "7499\n",
      "7999\n",
      "8499\n",
      "8999\n",
      "9499\n",
      "9999\n",
      "10499\n",
      "10999\n",
      "11499\n",
      "11999\n",
      "12499\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:33.413651Z",
     "start_time": "2024-12-03T03:44:33.411116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shape_items = list(shape_counts.items())\n",
    "shape_items.sort(key = lambda x: x[1])\n",
    "shape_items.reverse()"
   ],
   "id": "5b69870835ab88cc",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:33.422972Z",
     "start_time": "2024-12-03T03:44:33.420353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 10% of the data will be used for validation\n",
    "validation_size = 0.1\n",
    "img_size = IMG_SIZE # resize images to be 0.25x most common shape (374x500)\n",
    "num_channels = 3 # RGB\n",
    "sample_size = 25000 # Using all training data for the sample size"
   ],
   "id": "befa77817e53f517",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:33.464644Z",
     "start_time": "2024-12-03T03:44:33.430268Z"
    }
   },
   "cell_type": "code",
   "source": "len(glob.glob(cat_filepath))",
   "id": "d4f575950c1194d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:33.478787Z",
     "start_time": "2024-12-03T03:44:33.469830Z"
    }
   },
   "cell_type": "code",
   "source": "len(glob.glob(lion_filepath))",
   "id": "e780180d544a266f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2621"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:33.492412Z",
     "start_time": "2024-12-03T03:44:33.483815Z"
    }
   },
   "cell_type": "code",
   "source": "len(glob.glob(tiger_filepath))",
   "id": "ef7bd07116c73b4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2480"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:33.533300Z",
     "start_time": "2024-12-03T03:44:33.498305Z"
    }
   },
   "cell_type": "code",
   "source": "pixels_from_path(glob.glob(cat_filepath)[5]).shape",
   "id": "debf07bfdd96c957",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 94, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:44:33.541952Z",
     "start_time": "2024-12-03T03:44:33.538390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training size\n",
    "SAMPLE_SIZE = 11250\n",
    "SAMPLE_SIZE_TUNING = 2200    # different due to different dataset size\n",
    "\n",
    "# Validation size\n",
    "valid_size = 1250\n",
    "valid_size_tuning = 220      # different due to different dataset size"
   ],
   "id": "5474334af963daeb",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:02.653410Z",
     "start_time": "2024-12-03T03:44:33.552150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"loading training cat images...\")\n",
    "cat_train_set = compile_set(cat_filepath, SAMPLE_SIZE)\n",
    "\n",
    "print(\"loading training dog images...\")\n",
    "dog_train_set = compile_set(dog_filepath, SAMPLE_SIZE)\n",
    "\n",
    "print(\"loading training tiger images...\")\n",
    "tiger_train_set = compile_set(tiger_filepath, SAMPLE_SIZE_TUNING)\n",
    "\n",
    "print(\"loading training lion images...\")\n",
    "lion_train_set = compile_set(lion_filepath, SAMPLE_SIZE_TUNING)"
   ],
   "id": "fd1b6b9f23a9bc88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training cat images...\n",
      "loading training dog images...\n",
      "loading training tiger images...\n",
      "loading training lion images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachel\\IdeaProjects\\DLE305-Assessment-2\\.venv\\Lib\\site-packages\\PIL\\Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:11.711116Z",
     "start_time": "2024-12-03T03:46:02.685432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"loading validation cat images...\")\n",
    "cat_valid_set = compile_valid_set(cat_filepath, valid_size)\n",
    "\n",
    "print(\"loading validation dog images...\")\n",
    "dog_valid_set = compile_valid_set(dog_filepath, valid_size)\n",
    "\n",
    "print(\"loading training tiger images...\")\n",
    "tiger_valid_set = compile_valid_set(tiger_filepath, valid_size_tuning)\n",
    "\n",
    "print(\"loading training lion images...\")\n",
    "lion_valid_set = compile_valid_set(lion_filepath, valid_size_tuning)"
   ],
   "id": "76471bccf4621b6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading validation cat images...\n",
      "loading validation dog images...\n",
      "loading training tiger images...\n",
      "loading training lion images...\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:11.860600Z",
     "start_time": "2024-12-03T03:46:11.714108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train = np.concatenate([cat_train_set, dog_train_set])\n",
    "# Applying labels based on sample size because data are currently ordered by class\n",
    "labels_train = np.asarray([1 for _ in range(SAMPLE_SIZE)]+[0 for _ in range(SAMPLE_SIZE)])"
   ],
   "id": "cd74290b5d627755",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:11.905381Z",
     "start_time": "2024-12-03T03:46:11.875127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_tune = np.concatenate([tiger_train_set, lion_train_set])\n",
    "# Applying labels based on sample size because data are currently ordered by class\n",
    "labels_tune = np.asarray([1 for _ in range(SAMPLE_SIZE_TUNING)]+[0 for _ in range(SAMPLE_SIZE_TUNING)])"
   ],
   "id": "2176a0b4a3a2a514",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:11.937289Z",
     "start_time": "2024-12-03T03:46:11.919064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_valid = np.concatenate([cat_valid_set, dog_valid_set])\n",
    "# Applying labels based on validation sample size because data are currently ordered by class\n",
    "labels_valid = np.asarray([1 for _ in range(valid_size)]+[0 for _ in range(valid_size)])"
   ],
   "id": "95d6d6f8258fe360",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:11.957259Z",
     "start_time": "2024-12-03T03:46:11.950914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_valid_tune = np.concatenate([tiger_valid_set, lion_valid_set])\n",
    "# Applying labels based on validation sample size because data are currently ordered by class\n",
    "labels_valid_tune = np.asarray([1 for _ in range(valid_size_tuning)]+[0 for _ in range(valid_size_tuning)])"
   ],
   "id": "12bab1b0f03f406d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:11.976126Z",
     "start_time": "2024-12-03T03:46:11.972909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reshape labels to match output\n",
    "labels_train = labels_train.reshape(-1,1)\n",
    "labels_valid = labels_valid.reshape(-1,1)"
   ],
   "id": "8746156b1309df95",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:11.997021Z",
     "start_time": "2024-12-03T03:46:11.993695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels_tune = labels_tune.reshape(-1,1)\n",
    "labels_valid_tune = labels_valid_tune.reshape(-1,1)"
   ],
   "id": "738d5da27384d4f6",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:12.018830Z",
     "start_time": "2024-12-03T03:46:12.014833Z"
    }
   },
   "cell_type": "code",
   "source": "x_train.shape",
   "id": "a669bfba765875fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 125, 94, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:12.039439Z",
     "start_time": "2024-12-03T03:46:12.036076Z"
    }
   },
   "cell_type": "code",
   "source": "labels_train.shape",
   "id": "e761935e41582d0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:12.060008Z",
     "start_time": "2024-12-03T03:46:12.056105Z"
    }
   },
   "cell_type": "code",
   "source": "labels_train[:10]  # Checking values to ensure they're not None",
   "id": "fd5d1c2a8e2552",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:12.081364Z",
     "start_time": "2024-12-03T03:46:12.077906Z"
    }
   },
   "cell_type": "code",
   "source": "labels_train[22490:]  # Checking values to ensure they're not None",
   "id": "29a0ebd2a5e956fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:12.107607Z",
     "start_time": "2024-12-03T03:46:12.104865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fully connected layer neuron number\n",
    "fc_layer_size = 256"
   ],
   "id": "94a59741538511bd",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN from A2",
   "id": "a7d75a240e9be6bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:12.238914Z",
     "start_time": "2024-12-03T03:46:12.117576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convolution parameters\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "catdog_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)"
   ],
   "id": "223c6a634c4fa382",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T03:46:12.432563Z",
     "start_time": "2024-12-03T03:46:12.423087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=1e-6)\n",
    "catdog_model.compile(optimizer=customAdam,  # Optimizer\n",
    "                        # Loss function to minimize\n",
    "                        loss=\"BinaryCrossentropy\",\n",
    "                        # List of metrics to monitor\n",
    "                        metrics=[\"BinaryCrossentropy\",\"MeanSquaredError\", \"accuracy\"])"
   ],
   "id": "63f96b1617eda2ff",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:10:46.498193Z",
     "start_time": "2024-12-03T03:46:12.493614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = catdog_model.fit(x_train,\n",
    "                              labels_train,\n",
    "                              batch_size=64,\n",
    "                              shuffle = True,\n",
    "                              epochs=30,\n",
    "                              validation_data=(x_valid, labels_valid))"
   ],
   "id": "c0eeba8482494ca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m174s\u001B[0m 491ms/step - BinaryCrossentropy: 1.7523 - MeanSquaredError: 0.3841 - accuracy: 0.5280 - loss: 1.7523 - val_BinaryCrossentropy: 0.9549 - val_MeanSquaredError: 0.2865 - val_accuracy: 0.6040 - val_loss: 0.9549\n",
      "Epoch 2/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m171s\u001B[0m 486ms/step - BinaryCrossentropy: 0.9133 - MeanSquaredError: 0.2800 - accuracy: 0.6116 - loss: 0.9133 - val_BinaryCrossentropy: 0.8187 - val_MeanSquaredError: 0.2589 - val_accuracy: 0.6324 - val_loss: 0.8187\n",
      "Epoch 3/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m170s\u001B[0m 482ms/step - BinaryCrossentropy: 0.7693 - MeanSquaredError: 0.2490 - accuracy: 0.6392 - loss: 0.7693 - val_BinaryCrossentropy: 0.7608 - val_MeanSquaredError: 0.2460 - val_accuracy: 0.6388 - val_loss: 0.7608\n",
      "Epoch 4/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 481ms/step - BinaryCrossentropy: 0.6911 - MeanSquaredError: 0.2276 - accuracy: 0.6664 - loss: 0.6911 - val_BinaryCrossentropy: 0.8202 - val_MeanSquaredError: 0.2623 - val_accuracy: 0.6276 - val_loss: 0.8202\n",
      "Epoch 5/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m170s\u001B[0m 482ms/step - BinaryCrossentropy: 0.6569 - MeanSquaredError: 0.2167 - accuracy: 0.6807 - loss: 0.6569 - val_BinaryCrossentropy: 0.6728 - val_MeanSquaredError: 0.2217 - val_accuracy: 0.6772 - val_loss: 0.6728\n",
      "Epoch 6/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 480ms/step - BinaryCrossentropy: 0.5999 - MeanSquaredError: 0.1990 - accuracy: 0.7074 - loss: 0.5999 - val_BinaryCrossentropy: 0.6827 - val_MeanSquaredError: 0.2234 - val_accuracy: 0.6796 - val_loss: 0.6827\n",
      "Epoch 7/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 480ms/step - BinaryCrossentropy: 0.5646 - MeanSquaredError: 0.1866 - accuracy: 0.7232 - loss: 0.5646 - val_BinaryCrossentropy: 0.6418 - val_MeanSquaredError: 0.2104 - val_accuracy: 0.6988 - val_loss: 0.6418\n",
      "Epoch 8/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 480ms/step - BinaryCrossentropy: 0.5385 - MeanSquaredError: 0.1780 - accuracy: 0.7383 - loss: 0.5385 - val_BinaryCrossentropy: 0.6592 - val_MeanSquaredError: 0.2153 - val_accuracy: 0.6860 - val_loss: 0.6592\n",
      "Epoch 9/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 481ms/step - BinaryCrossentropy: 0.5079 - MeanSquaredError: 0.1668 - accuracy: 0.7549 - loss: 0.5079 - val_BinaryCrossentropy: 0.6333 - val_MeanSquaredError: 0.2067 - val_accuracy: 0.6988 - val_loss: 0.6333\n",
      "Epoch 10/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 479ms/step - BinaryCrossentropy: 0.4974 - MeanSquaredError: 0.1628 - accuracy: 0.7634 - loss: 0.4974 - val_BinaryCrossentropy: 0.6352 - val_MeanSquaredError: 0.2065 - val_accuracy: 0.7040 - val_loss: 0.6352\n",
      "Epoch 11/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 479ms/step - BinaryCrossentropy: 0.4688 - MeanSquaredError: 0.1540 - accuracy: 0.7728 - loss: 0.4688 - val_BinaryCrossentropy: 0.6149 - val_MeanSquaredError: 0.2009 - val_accuracy: 0.7180 - val_loss: 0.6149\n",
      "Epoch 12/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 479ms/step - BinaryCrossentropy: 0.4438 - MeanSquaredError: 0.1442 - accuracy: 0.7910 - loss: 0.4438 - val_BinaryCrossentropy: 0.6099 - val_MeanSquaredError: 0.1972 - val_accuracy: 0.7152 - val_loss: 0.6099\n",
      "Epoch 13/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 479ms/step - BinaryCrossentropy: 0.4378 - MeanSquaredError: 0.1415 - accuracy: 0.7971 - loss: 0.4378 - val_BinaryCrossentropy: 0.6064 - val_MeanSquaredError: 0.1960 - val_accuracy: 0.7168 - val_loss: 0.6064\n",
      "Epoch 14/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 479ms/step - BinaryCrossentropy: 0.4019 - MeanSquaredError: 0.1285 - accuracy: 0.8171 - loss: 0.4019 - val_BinaryCrossentropy: 0.6160 - val_MeanSquaredError: 0.1986 - val_accuracy: 0.7204 - val_loss: 0.6160\n",
      "Epoch 15/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 479ms/step - BinaryCrossentropy: 0.3881 - MeanSquaredError: 0.1238 - accuracy: 0.8242 - loss: 0.3881 - val_BinaryCrossentropy: 0.6459 - val_MeanSquaredError: 0.2071 - val_accuracy: 0.7020 - val_loss: 0.6459\n",
      "Epoch 16/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 481ms/step - BinaryCrossentropy: 0.3674 - MeanSquaredError: 0.1163 - accuracy: 0.8391 - loss: 0.3674 - val_BinaryCrossentropy: 0.6021 - val_MeanSquaredError: 0.1932 - val_accuracy: 0.7260 - val_loss: 0.6021\n",
      "Epoch 17/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 481ms/step - BinaryCrossentropy: 0.3601 - MeanSquaredError: 0.1129 - accuracy: 0.8447 - loss: 0.3601 - val_BinaryCrossentropy: 0.6190 - val_MeanSquaredError: 0.1957 - val_accuracy: 0.7248 - val_loss: 0.6190\n",
      "Epoch 18/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 480ms/step - BinaryCrossentropy: 0.3526 - MeanSquaredError: 0.1105 - accuracy: 0.8447 - loss: 0.3526 - val_BinaryCrossentropy: 0.6033 - val_MeanSquaredError: 0.1919 - val_accuracy: 0.7288 - val_loss: 0.6033\n",
      "Epoch 19/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 478ms/step - BinaryCrossentropy: 0.3299 - MeanSquaredError: 0.1021 - accuracy: 0.8599 - loss: 0.3299 - val_BinaryCrossentropy: 0.5997 - val_MeanSquaredError: 0.1907 - val_accuracy: 0.7356 - val_loss: 0.5997\n",
      "Epoch 20/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 479ms/step - BinaryCrossentropy: 0.3166 - MeanSquaredError: 0.0973 - accuracy: 0.8689 - loss: 0.3166 - val_BinaryCrossentropy: 0.6200 - val_MeanSquaredError: 0.1973 - val_accuracy: 0.7200 - val_loss: 0.6200\n",
      "Epoch 21/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 479ms/step - BinaryCrossentropy: 0.2994 - MeanSquaredError: 0.0906 - accuracy: 0.8787 - loss: 0.2994 - val_BinaryCrossentropy: 0.6057 - val_MeanSquaredError: 0.1899 - val_accuracy: 0.7308 - val_loss: 0.6057\n",
      "Epoch 22/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 479ms/step - BinaryCrossentropy: 0.2844 - MeanSquaredError: 0.0854 - accuracy: 0.8869 - loss: 0.2844 - val_BinaryCrossentropy: 0.5917 - val_MeanSquaredError: 0.1856 - val_accuracy: 0.7380 - val_loss: 0.5917\n",
      "Epoch 23/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 479ms/step - BinaryCrossentropy: 0.2840 - MeanSquaredError: 0.0854 - accuracy: 0.8855 - loss: 0.2840 - val_BinaryCrossentropy: 0.6094 - val_MeanSquaredError: 0.1887 - val_accuracy: 0.7292 - val_loss: 0.6094\n",
      "Epoch 24/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 479ms/step - BinaryCrossentropy: 0.2618 - MeanSquaredError: 0.0774 - accuracy: 0.9009 - loss: 0.2618 - val_BinaryCrossentropy: 0.5884 - val_MeanSquaredError: 0.1836 - val_accuracy: 0.7440 - val_loss: 0.5884\n",
      "Epoch 25/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 479ms/step - BinaryCrossentropy: 0.2516 - MeanSquaredError: 0.0732 - accuracy: 0.9071 - loss: 0.2516 - val_BinaryCrossentropy: 0.5883 - val_MeanSquaredError: 0.1832 - val_accuracy: 0.7480 - val_loss: 0.5883\n",
      "Epoch 26/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 478ms/step - BinaryCrossentropy: 0.2462 - MeanSquaredError: 0.0719 - accuracy: 0.9072 - loss: 0.2462 - val_BinaryCrossentropy: 0.6016 - val_MeanSquaredError: 0.1866 - val_accuracy: 0.7344 - val_loss: 0.6016\n",
      "Epoch 27/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 479ms/step - BinaryCrossentropy: 0.2321 - MeanSquaredError: 0.0668 - accuracy: 0.9173 - loss: 0.2321 - val_BinaryCrossentropy: 0.5902 - val_MeanSquaredError: 0.1826 - val_accuracy: 0.7412 - val_loss: 0.5902\n",
      "Epoch 28/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m170s\u001B[0m 482ms/step - BinaryCrossentropy: 0.2210 - MeanSquaredError: 0.0627 - accuracy: 0.9215 - loss: 0.2210 - val_BinaryCrossentropy: 0.6045 - val_MeanSquaredError: 0.1851 - val_accuracy: 0.7428 - val_loss: 0.6045\n",
      "Epoch 29/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 481ms/step - BinaryCrossentropy: 0.2067 - MeanSquaredError: 0.0576 - accuracy: 0.9283 - loss: 0.2067 - val_BinaryCrossentropy: 0.5972 - val_MeanSquaredError: 0.1839 - val_accuracy: 0.7432 - val_loss: 0.5972\n",
      "Epoch 30/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m170s\u001B[0m 482ms/step - BinaryCrossentropy: 0.2073 - MeanSquaredError: 0.0578 - accuracy: 0.9303 - loss: 0.2073 - val_BinaryCrossentropy: 0.6011 - val_MeanSquaredError: 0.1820 - val_accuracy: 0.7500 - val_loss: 0.6011\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:10:51.018192Z",
     "start_time": "2024-12-03T05:10:46.555281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluating CNN model predictions on validation data\n",
    "\n",
    "#preds = np.asarray(preds).flatten()\n",
    "labels_flat = np.asarray(labels_valid).flatten()\n",
    "\n",
    "preds = catdog_model.predict(x_valid)\n",
    "preds = np.asarray([pred[0] for pred in preds])\n",
    "\n",
    "np.corrcoef(preds, labels_flat)"
   ],
   "id": "5997704ed27030a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 55ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.55800595],\n",
       "       [0.55800595, 1.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:10:51.045007Z",
     "start_time": "2024-12-03T05:10:51.039791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MSE for predictions\n",
    "# Closer to 0 is better\n",
    "print(mean_squared_error(labels_flat, preds))"
   ],
   "id": "8915936392a75461",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1819567997760077\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:10:51.094685Z",
     "start_time": "2024-12-03T05:10:51.085562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Receiver Operating Characteristic and Area Under Curve\n",
    "# Closer to 1 is better\n",
    "print(roc_auc_score(labels_flat, preds))"
   ],
   "id": "d2173a820c454fe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82149952\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:10:51.776809Z",
     "start_time": "2024-12-03T05:10:51.136547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Saving model\n",
    "catdog_model.save('untuned_model.keras')"
   ],
   "id": "f55ed7f1c0879b8f",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fine-tuning model on big cats",
   "id": "138c438e3f6c5b54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:10:52.060716Z",
     "start_time": "2024-12-03T05:10:51.794391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading model to variable\n",
    "untuned_model = keras.models.load_model('untuned_model.keras')"
   ],
   "id": "d7257f79f44453b5",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:10:52.080283Z",
     "start_time": "2024-12-03T05:10:52.077618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in untuned_model.layers:\n",
    "    if isinstance(layer, layers.Conv2D):\n",
    "        layer.trainable = False"
   ],
   "id": "4a5382b8c197d53a",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:10:52.126865Z",
     "start_time": "2024-12-03T05:10:52.097834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove classification head\n",
    "conv_x = untuned_model.get_layer(\"flattened_features\").output\n",
    "\n",
    "# Add new dense layers for big cats\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='new_fc')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='bigcat_class')(conv_x)\n",
    "\n",
    "# Create new model\n",
    "bigcat_model = keras.Model(inputs=untuned_model.input, outputs=conv_outputs)"
   ],
   "id": "54c87d75cdc1926c",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:10:52.148131Z",
     "start_time": "2024-12-03T05:10:52.143673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=1e-6)  # Small learning rate for transfer learning\n",
    "bigcat_model.compile(optimizer=customAdam,\n",
    "                         loss=\"BinaryCrossentropy\",\n",
    "                         metrics=[\"BinaryCrossentropy\",\"MeanSquaredError\", \"accuracy\"])"
   ],
   "id": "851dfc5eb12416bf",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:14:27.418281Z",
     "start_time": "2024-12-03T05:10:52.165730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = bigcat_model.fit(x_tune,\n",
    "                               labels_tune,\n",
    "                               batch_size=64,\n",
    "                               shuffle=True,\n",
    "                               epochs=15,  # Start with fewer epochs\n",
    "                               validation_data=(x_valid_tune, labels_valid_tune))"
   ],
   "id": "6f65d2cd871b5583",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 211ms/step - BinaryCrossentropy: 5.3465 - MeanSquaredError: 0.4190 - accuracy: 0.5501 - loss: 5.3465 - val_BinaryCrossentropy: 1.9373 - val_MeanSquaredError: 0.3217 - val_accuracy: 0.6295 - val_loss: 1.9373\n",
      "Epoch 2/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 208ms/step - BinaryCrossentropy: 1.4952 - MeanSquaredError: 0.2658 - accuracy: 0.6829 - loss: 1.4952 - val_BinaryCrossentropy: 1.4965 - val_MeanSquaredError: 0.2723 - val_accuracy: 0.7000 - val_loss: 1.4965\n",
      "Epoch 3/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 207ms/step - BinaryCrossentropy: 1.1286 - MeanSquaredError: 0.2279 - accuracy: 0.7252 - loss: 1.1286 - val_BinaryCrossentropy: 1.2901 - val_MeanSquaredError: 0.2447 - val_accuracy: 0.7068 - val_loss: 1.2901\n",
      "Epoch 4/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 207ms/step - BinaryCrossentropy: 0.9938 - MeanSquaredError: 0.2102 - accuracy: 0.7442 - loss: 0.9938 - val_BinaryCrossentropy: 1.1559 - val_MeanSquaredError: 0.2324 - val_accuracy: 0.7364 - val_loss: 1.1559\n",
      "Epoch 5/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 207ms/step - BinaryCrossentropy: 0.8667 - MeanSquaredError: 0.1831 - accuracy: 0.7756 - loss: 0.8667 - val_BinaryCrossentropy: 1.1390 - val_MeanSquaredError: 0.2275 - val_accuracy: 0.7432 - val_loss: 1.1390\n",
      "Epoch 6/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 207ms/step - BinaryCrossentropy: 0.7019 - MeanSquaredError: 0.1651 - accuracy: 0.7889 - loss: 0.7019 - val_BinaryCrossentropy: 1.0706 - val_MeanSquaredError: 0.2250 - val_accuracy: 0.7364 - val_loss: 1.0706\n",
      "Epoch 7/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 207ms/step - BinaryCrossentropy: 0.6424 - MeanSquaredError: 0.1457 - accuracy: 0.8180 - loss: 0.6424 - val_BinaryCrossentropy: 1.0454 - val_MeanSquaredError: 0.2164 - val_accuracy: 0.7409 - val_loss: 1.0454\n",
      "Epoch 8/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 207ms/step - BinaryCrossentropy: 0.6215 - MeanSquaredError: 0.1440 - accuracy: 0.8217 - loss: 0.6215 - val_BinaryCrossentropy: 1.0409 - val_MeanSquaredError: 0.2199 - val_accuracy: 0.7364 - val_loss: 1.0409\n",
      "Epoch 9/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 207ms/step - BinaryCrossentropy: 0.4777 - MeanSquaredError: 0.1184 - accuracy: 0.8479 - loss: 0.4777 - val_BinaryCrossentropy: 1.0750 - val_MeanSquaredError: 0.2209 - val_accuracy: 0.7318 - val_loss: 1.0750\n",
      "Epoch 10/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 208ms/step - BinaryCrossentropy: 0.4836 - MeanSquaredError: 0.1162 - accuracy: 0.8533 - loss: 0.4836 - val_BinaryCrossentropy: 0.9309 - val_MeanSquaredError: 0.2025 - val_accuracy: 0.7545 - val_loss: 0.9309\n",
      "Epoch 11/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 206ms/step - BinaryCrossentropy: 0.4040 - MeanSquaredError: 0.1054 - accuracy: 0.8627 - loss: 0.4040 - val_BinaryCrossentropy: 0.9321 - val_MeanSquaredError: 0.2032 - val_accuracy: 0.7523 - val_loss: 0.9321\n",
      "Epoch 12/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 206ms/step - BinaryCrossentropy: 0.3938 - MeanSquaredError: 0.1023 - accuracy: 0.8619 - loss: 0.3938 - val_BinaryCrossentropy: 0.9056 - val_MeanSquaredError: 0.1980 - val_accuracy: 0.7705 - val_loss: 0.9056\n",
      "Epoch 13/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 207ms/step - BinaryCrossentropy: 0.3443 - MeanSquaredError: 0.0851 - accuracy: 0.8885 - loss: 0.3443 - val_BinaryCrossentropy: 0.9154 - val_MeanSquaredError: 0.1961 - val_accuracy: 0.7614 - val_loss: 0.9154\n",
      "Epoch 14/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 208ms/step - BinaryCrossentropy: 0.3118 - MeanSquaredError: 0.0811 - accuracy: 0.8963 - loss: 0.3118 - val_BinaryCrossentropy: 0.8652 - val_MeanSquaredError: 0.1898 - val_accuracy: 0.7841 - val_loss: 0.8652\n",
      "Epoch 15/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 208ms/step - BinaryCrossentropy: 0.2594 - MeanSquaredError: 0.0708 - accuracy: 0.9083 - loss: 0.2594 - val_BinaryCrossentropy: 0.9864 - val_MeanSquaredError: 0.2157 - val_accuracy: 0.7455 - val_loss: 0.9864\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:14:28.319234Z",
     "start_time": "2024-12-03T05:14:27.453714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluating finetuned model predictions on validation data\n",
    "labels_flat = np.asarray(labels_valid_tune).flatten()\n",
    "preds = bigcat_model.predict(x_valid_tune)\n",
    "preds = np.asarray([pred[0] for pred in preds])\n",
    "\n",
    "print(np.corrcoef(preds, labels_flat))"
   ],
   "id": "b1eb3cd6f2af7a2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step\n",
      "[[1.         0.53297937]\n",
      " [0.53297937 1.        ]]\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:14:28.342646Z",
     "start_time": "2024-12-03T05:14:28.339187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MSE for predictions\n",
    "# Closer to 0 is better\n",
    "print(mean_squared_error(labels_flat, preds))"
   ],
   "id": "2d911417d1643a3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2157295587663383\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:14:28.348736Z",
     "start_time": "2024-12-03T05:14:28.345637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Receiver Operating Characteristic and Area Under Curve\n",
    "# Closer to 1 is better\n",
    "print(roc_auc_score(labels_flat, preds))"
   ],
   "id": "e85c86bf07adecf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8334504132231404\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:14:29.025590Z",
     "start_time": "2024-12-03T05:14:28.366152Z"
    }
   },
   "cell_type": "code",
   "source": "bigcat_model.save(\"tuned_model.keras\")",
   "id": "6392a17e0da35281",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Optional for larger datasets",
   "id": "7bb6354574a77e18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:14:29.046374Z",
     "start_time": "2024-12-03T05:14:29.043486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in bigcat_model.layers:\n",
    "    if isinstance(layer, layers.Conv2D):\n",
    "        layer.trainable = True  # Unfreeze convolutional layers"
   ],
   "id": "cb3b88eea80be47a",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:17:14.659798Z",
     "start_time": "2024-12-03T05:14:29.064217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=1e-7)  # Even smaller learning rate\n",
    "bigcat_model.compile(optimizer=customAdam,\n",
    "                         loss=\"BinaryCrossentropy\",\n",
    "                         metrics=[\"BinaryCrossentropy\",\"MeanSquaredError\", \"accuracy\"])\n",
    "\n",
    "history_fine = bigcat_model.fit(x_tune,\n",
    "                                    labels_tune,\n",
    "                                    batch_size=64,\n",
    "                                    shuffle=True,\n",
    "                                    epochs=5,       # Fewer epochs\n",
    "                                    validation_data=(x_valid_tune, labels_valid_tune))"
   ],
   "id": "7b5ede7a699582ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 477ms/step - BinaryCrossentropy: 0.2492 - MeanSquaredError: 0.0628 - accuracy: 0.9227 - loss: 0.2492 - val_BinaryCrossentropy: 0.8614 - val_MeanSquaredError: 0.1926 - val_accuracy: 0.7659 - val_loss: 0.8614\n",
      "Epoch 2/5\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 479ms/step - BinaryCrossentropy: 0.2333 - MeanSquaredError: 0.0591 - accuracy: 0.9264 - loss: 0.2333 - val_BinaryCrossentropy: 0.8515 - val_MeanSquaredError: 0.1889 - val_accuracy: 0.7750 - val_loss: 0.8515\n",
      "Epoch 3/5\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 477ms/step - BinaryCrossentropy: 0.2125 - MeanSquaredError: 0.0555 - accuracy: 0.9303 - loss: 0.2125 - val_BinaryCrossentropy: 0.8437 - val_MeanSquaredError: 0.1878 - val_accuracy: 0.7773 - val_loss: 0.8437\n",
      "Epoch 4/5\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 478ms/step - BinaryCrossentropy: 0.1987 - MeanSquaredError: 0.0547 - accuracy: 0.9304 - loss: 0.1987 - val_BinaryCrossentropy: 0.8395 - val_MeanSquaredError: 0.1874 - val_accuracy: 0.7773 - val_loss: 0.8395\n",
      "Epoch 5/5\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 477ms/step - BinaryCrossentropy: 0.2074 - MeanSquaredError: 0.0546 - accuracy: 0.9322 - loss: 0.2074 - val_BinaryCrossentropy: 0.8652 - val_MeanSquaredError: 0.1957 - val_accuracy: 0.7386 - val_loss: 0.8652\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:17:15.562538Z",
     "start_time": "2024-12-03T05:17:14.696339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluating finetuned model predictions on validation data\n",
    "labels_flat = np.asarray(labels_valid_tune).flatten()\n",
    "preds = bigcat_model.predict(x_valid_tune)\n",
    "preds = np.asarray([pred[0] for pred in preds])\n",
    "\n",
    "print(np.corrcoef(preds, labels_flat))"
   ],
   "id": "23914d7c0218596",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step\n",
      "[[1.         0.56668521]\n",
      " [0.56668521 1.        ]]\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:17:15.568395Z",
     "start_time": "2024-12-03T05:17:15.565532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MSE for predictions\n",
    "# Closer to 0 is better\n",
    "print(mean_squared_error(labels_flat, preds))"
   ],
   "id": "f16e3e204c3b898",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19567262130401053\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:17:15.589982Z",
     "start_time": "2024-12-03T05:17:15.586051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Receiver Operating Characteristic and Area Under Curve\n",
    "# Closer to 1 is better\n",
    "print(roc_auc_score(labels_flat, preds))"
   ],
   "id": "3a97d38c407076e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8433677685950413\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:17:16.290511Z",
     "start_time": "2024-12-03T05:17:15.607250Z"
    }
   },
   "cell_type": "code",
   "source": "bigcat_model.save(\"retuned_model.keras\")",
   "id": "1478488850e12b89",
   "outputs": [],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
