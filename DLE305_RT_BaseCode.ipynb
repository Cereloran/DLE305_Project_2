{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing libraries",
   "id": "a54d8ceace5470a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:17:48.741262Z",
     "start_time": "2024-12-02T11:17:33.136873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run if not everything installed\n",
    "!pip install tensorflow     > null 2>&1\n",
    "!pip install seaborn        > null 2>&1\n",
    "!pip install numpy          > null 2>&1\n",
    "!pip install pillow         > null 2>&1\n",
    "!pip install opencv-python  > null 2>&1\n",
    "!pip install scikit-learn   > null 2>&1\n",
    "#!pip install torchvision    > null 2>&1"
   ],
   "id": "18ac763866e90644",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:05:28.830647Z",
     "start_time": "2024-12-02T09:05:24.377973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#import tensorflow as tf\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, classification_report\n",
    "\n",
    "# from torchvision.transforms import (\n",
    "#     Compose,\n",
    "#     RandomHorizontalFlip,\n",
    "#     RandomRotation,\n",
    "# )"
   ],
   "id": "6d41e5de45384b4b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing",
   "id": "92dc9decc5d984fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:12:36.384898Z",
     "start_time": "2024-12-02T09:12:36.381925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specifying final image size and resizing to that size\n",
    "IMG_SIZE = (94, 125)\n",
    "def pixels_from_path(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    im = im.convert(\"RGB\")\n",
    "    im = im.resize(IMG_SIZE)\n",
    "    np_im = np.array(im)\n",
    "    # Returns 3D array of RGB values for image\n",
    "    return np_im"
   ],
   "id": "3c87fafffcd5fd2a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:05:31.933479Z",
     "start_time": "2024-12-02T09:05:31.930598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Input relevant filepath before '/cat'\n",
    "cat_filepath = 'cat/*'\n",
    "dog_filepath = 'dog/*'\n",
    "tiger_filepath = 'tiger/*'\n",
    "lion_filepath = 'lion/*'"
   ],
   "id": "3d223d9db0129e42",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:05:54.050429Z",
     "start_time": "2024-12-02T09:05:33.054734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shape_counts = defaultdict(int)\n",
    "for i, cat in enumerate(glob.glob(cat_filepath)):\n",
    "    # Will print iteration no. if i+1 is a multiple of 500\n",
    "    if (i+1)%500==0:\n",
    "        print(i)\n",
    "    img_shape = pixels_from_path(cat).shape\n",
    "    shape_counts[str(img_shape)]= shape_counts[str(img_shape)]+ 1"
   ],
   "id": "420418a30617bb12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "999\n",
      "1499\n",
      "1999\n",
      "2499\n",
      "2999\n",
      "3499\n",
      "3999\n",
      "4499\n",
      "4999\n",
      "5499\n",
      "5999\n",
      "6499\n",
      "6999\n",
      "7499\n",
      "7999\n",
      "8499\n",
      "8999\n",
      "9499\n",
      "9999\n",
      "10499\n",
      "10999\n",
      "11499\n",
      "11999\n",
      "12499\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:05:54.099888Z",
     "start_time": "2024-12-02T09:05:54.096667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shape_items = list(shape_counts.items())\n",
    "shape_items.sort(key = lambda x: x[1])\n",
    "shape_items.reverse()"
   ],
   "id": "5b69870835ab88cc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:05:54.154858Z",
     "start_time": "2024-12-02T09:05:54.152714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 10% of the data will be used for validation\n",
    "validation_size = 0.1\n",
    "img_size = IMG_SIZE # resize images to be 0.25x most common shape (374x500)\n",
    "num_channels = 3 # RGB\n",
    "sample_size = 25000 # Using all training data for the sample size"
   ],
   "id": "befa77817e53f517",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:05:54.241748Z",
     "start_time": "2024-12-02T09:05:54.202578Z"
    }
   },
   "cell_type": "code",
   "source": "len(glob.glob(cat_filepath))",
   "id": "d4f575950c1194d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:05:54.336406Z",
     "start_time": "2024-12-02T09:05:54.326071Z"
    }
   },
   "cell_type": "code",
   "source": "len(glob.glob(lion_filepath))",
   "id": "e780180d544a266f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2621"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:05:54.440930Z",
     "start_time": "2024-12-02T09:05:54.428999Z"
    }
   },
   "cell_type": "code",
   "source": "len(glob.glob(tiger_filepath))",
   "id": "ef7bd07116c73b4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2480"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:05:54.560640Z",
     "start_time": "2024-12-02T09:05:54.521433Z"
    }
   },
   "cell_type": "code",
   "source": "pixels_from_path(glob.glob(cat_filepath)[5]).shape",
   "id": "debf07bfdd96c957",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 94, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:06:09.611605Z",
     "start_time": "2024-12-02T09:06:09.608382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training size\n",
    "SAMPLE_SIZE = 11250\n",
    "SAMPLE_SIZE_TUNING = 2200    # different due to different dataset size\n",
    "\n",
    "# Validation size\n",
    "valid_size = 1250\n",
    "valid_size_tuning = 220      # different due to different dataset size"
   ],
   "id": "5474334af963daeb",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:07:42.924287Z",
     "start_time": "2024-12-02T11:06:17.763511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"loading training cat images...\")\n",
    "cat_train_set = np.asarray([\n",
    "    pixels_from_path(cat)\n",
    "    for cat in glob.glob(cat_filepath)[:SAMPLE_SIZE]\n",
    "    if pixels_from_path(cat) is not None\n",
    "])\n",
    "\n",
    "print(\"loading training dog images...\")\n",
    "dog_train_set = np.asarray([\n",
    "    pixels_from_path(dog)\n",
    "    for dog in glob.glob(dog_filepath)[:SAMPLE_SIZE]\n",
    "    if pixels_from_path(dog) is not None\n",
    "])\n",
    "\n",
    "print(\"loading training tiger images...\")\n",
    "tiger_train_set = np.asarray([\n",
    "    pixels_from_path(tiger)\n",
    "    for tiger in glob.glob(tiger_filepath)[:SAMPLE_SIZE_TUNING]\n",
    "    if pixels_from_path(tiger) is not None\n",
    "])\n",
    "\n",
    "print(\"loading training lion images...\")\n",
    "lion_train_set = np.asarray([\n",
    "    pixels_from_path(lion)\n",
    "    for lion in glob.glob(lion_filepath)[:SAMPLE_SIZE_TUNING]\n",
    "    if pixels_from_path(lion) is not None\n",
    "])"
   ],
   "id": "fd1b6b9f23a9bc88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training cat images...\n",
      "loading training dog images...\n",
      "loading training tiger images...\n",
      "loading training lion images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachel\\IdeaProjects\\DLE305-Assessment-2\\.venv\\Lib\\site-packages\\PIL\\Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:34:39.633975Z",
     "start_time": "2024-12-02T09:34:30.117143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"loading validation cat images...\")\n",
    "cat_valid_set = np.asarray([\n",
    "    pixels_from_path(cat)\n",
    "    for cat in glob.glob(cat_filepath)[-valid_size:]\n",
    "    if pixels_from_path(cat) is not None\n",
    "])\n",
    "\n",
    "print(\"loading validation dog images...\")\n",
    "dog_valid_set = np.asarray([\n",
    "    pixels_from_path(dog)\n",
    "    for dog in glob.glob(dog_filepath)[-valid_size:]\n",
    "    if pixels_from_path(dog) is not None\n",
    "])\n",
    "\n",
    "print(\"loading training tiger images...\")\n",
    "tiger_valid_set = np.asarray([\n",
    "    pixels_from_path(tiger)\n",
    "    for tiger in glob.glob(tiger_filepath)[-valid_size_tuning:]\n",
    "    if pixels_from_path(tiger) is not None\n",
    "])\n",
    "\n",
    "print(\"loading training lion images...\")\n",
    "lion_valid_set = np.asarray([\n",
    "    pixels_from_path(lion)\n",
    "    for lion in glob.glob(lion_filepath)[-valid_size_tuning:]\n",
    "    if pixels_from_path(lion) is not None\n",
    "])"
   ],
   "id": "76471bccf4621b6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading validation cat images...\n",
      "loading validation dog images...\n",
      "loading training tiger images...\n",
      "loading training lion images...\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:34:55.982510Z",
     "start_time": "2024-12-02T09:34:55.857779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train = np.concatenate([cat_train_set, dog_train_set])\n",
    "# Applying labels based on sample size because data are currently ordered by class\n",
    "labels_train = np.asarray([1 for _ in range(SAMPLE_SIZE)]+[0 for _ in range(SAMPLE_SIZE)])"
   ],
   "id": "cd74290b5d627755",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:07:42.986353Z",
     "start_time": "2024-12-02T11:07:42.957379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_tune = np.concatenate([tiger_train_set, lion_train_set])\n",
    "# Applying labels based on sample size because data are currently ordered by class\n",
    "labels_tune = np.asarray([1 for _ in range(SAMPLE_SIZE_TUNING)]+[0 for _ in range(SAMPLE_SIZE_TUNING)])"
   ],
   "id": "2176a0b4a3a2a514",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:34:58.362500Z",
     "start_time": "2024-12-02T09:34:58.343879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_valid = np.concatenate([cat_valid_set, dog_valid_set])\n",
    "# Applying labels based on validation sample size because data are currently ordered by class\n",
    "labels_valid = np.asarray([1 for _ in range(valid_size)]+[0 for _ in range(valid_size)])"
   ],
   "id": "95d6d6f8258fe360",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:34:59.856628Z",
     "start_time": "2024-12-02T09:34:59.850084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_valid_tune = np.concatenate([tiger_valid_set, lion_valid_set])\n",
    "# Applying labels based on validation sample size because data are currently ordered by class\n",
    "labels_valid_tune = np.asarray([1 for _ in range(valid_size_tuning)]+[0 for _ in range(valid_size_tuning)])"
   ],
   "id": "12bab1b0f03f406d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:35:01.751866Z",
     "start_time": "2024-12-02T09:35:01.749147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reshape labels to match output\n",
    "labels_train = labels_train.reshape(-1,1)\n",
    "labels_valid = labels_valid.reshape(-1,1)"
   ],
   "id": "8746156b1309df95",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:07:42.995759Z",
     "start_time": "2024-12-02T11:07:42.993332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels_tune = labels_tune.reshape(-1,1)\n",
    "labels_valid_tune = labels_valid_tune.reshape(-1,1)"
   ],
   "id": "738d5da27384d4f6",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:35:05.523682Z",
     "start_time": "2024-12-02T09:35:05.520609Z"
    }
   },
   "cell_type": "code",
   "source": "x_train.shape",
   "id": "a669bfba765875fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 125, 94, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:35:07.025055Z",
     "start_time": "2024-12-02T09:35:07.021916Z"
    }
   },
   "cell_type": "code",
   "source": "labels_train.shape",
   "id": "e761935e41582d0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:35:09.197252Z",
     "start_time": "2024-12-02T09:35:09.194078Z"
    }
   },
   "cell_type": "code",
   "source": "labels_train[:10]  # Checking values to ensure they're not None",
   "id": "fd5d1c2a8e2552",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:35:13.427021Z",
     "start_time": "2024-12-02T09:35:13.423563Z"
    }
   },
   "cell_type": "code",
   "source": "labels_train[22490:]  # Checking values to ensure they're not None",
   "id": "29a0ebd2a5e956fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:35:19.143487Z",
     "start_time": "2024-12-02T09:35:19.140370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fully connected layer neuron number\n",
    "fc_layer_size = 256"
   ],
   "id": "94a59741538511bd",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN from A2",
   "id": "a7d75a240e9be6bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:35:21.305731Z",
     "start_time": "2024-12-02T09:35:21.185400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convolution parameters\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "catdog_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)"
   ],
   "id": "223c6a634c4fa382",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T09:35:23.819993Z",
     "start_time": "2024-12-02T09:35:23.811222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=1e-6)\n",
    "catdog_model.compile(optimizer=customAdam,  # Optimizer\n",
    "                        # Loss function to minimize\n",
    "                        loss=\"BinaryCrossentropy\",\n",
    "                        # List of metrics to monitor\n",
    "                        metrics=[\"BinaryCrossentropy\",\"MeanSquaredError\", \"accuracy\"])"
   ],
   "id": "63f96b1617eda2ff",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:01:04.956039Z",
     "start_time": "2024-12-02T09:35:25.714497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = catdog_model.fit(x_train,\n",
    "                              labels_train,\n",
    "                              batch_size=64,\n",
    "                              shuffle = True,\n",
    "                              epochs=30,\n",
    "                              validation_data=(x_valid, labels_valid))"
   ],
   "id": "c0eeba8482494ca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m172s\u001B[0m 485ms/step - BinaryCrossentropy: 1.4450 - MeanSquaredError: 0.3546 - accuracy: 0.5379 - loss: 1.4450 - val_BinaryCrossentropy: 0.8324 - val_MeanSquaredError: 0.2705 - val_accuracy: 0.6148 - val_loss: 0.8324\n",
      "Epoch 2/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m171s\u001B[0m 485ms/step - BinaryCrossentropy: 0.7920 - MeanSquaredError: 0.2599 - accuracy: 0.6186 - loss: 0.7920 - val_BinaryCrossentropy: 0.7302 - val_MeanSquaredError: 0.2441 - val_accuracy: 0.6388 - val_loss: 0.7302\n",
      "Epoch 3/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m170s\u001B[0m 484ms/step - BinaryCrossentropy: 0.6909 - MeanSquaredError: 0.2323 - accuracy: 0.6512 - loss: 0.6909 - val_BinaryCrossentropy: 0.6932 - val_MeanSquaredError: 0.2321 - val_accuracy: 0.6412 - val_loss: 0.6932\n",
      "Epoch 4/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 478ms/step - BinaryCrossentropy: 0.6443 - MeanSquaredError: 0.2171 - accuracy: 0.6742 - loss: 0.6443 - val_BinaryCrossentropy: 0.6702 - val_MeanSquaredError: 0.2243 - val_accuracy: 0.6620 - val_loss: 0.6702\n",
      "Epoch 5/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 479ms/step - BinaryCrossentropy: 0.5953 - MeanSquaredError: 0.2000 - accuracy: 0.7015 - loss: 0.5953 - val_BinaryCrossentropy: 0.6448 - val_MeanSquaredError: 0.2160 - val_accuracy: 0.6756 - val_loss: 0.6448\n",
      "Epoch 6/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 478ms/step - BinaryCrossentropy: 0.5682 - MeanSquaredError: 0.1902 - accuracy: 0.7176 - loss: 0.5682 - val_BinaryCrossentropy: 0.6407 - val_MeanSquaredError: 0.2133 - val_accuracy: 0.6860 - val_loss: 0.6407\n",
      "Epoch 7/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 478ms/step - BinaryCrossentropy: 0.5436 - MeanSquaredError: 0.1819 - accuracy: 0.7273 - loss: 0.5436 - val_BinaryCrossentropy: 0.6192 - val_MeanSquaredError: 0.2062 - val_accuracy: 0.6912 - val_loss: 0.6192\n",
      "Epoch 8/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 478ms/step - BinaryCrossentropy: 0.5214 - MeanSquaredError: 0.1737 - accuracy: 0.7389 - loss: 0.5214 - val_BinaryCrossentropy: 0.6413 - val_MeanSquaredError: 0.2117 - val_accuracy: 0.6944 - val_loss: 0.6413\n",
      "Epoch 9/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 477ms/step - BinaryCrossentropy: 0.4953 - MeanSquaredError: 0.1635 - accuracy: 0.7584 - loss: 0.4953 - val_BinaryCrossentropy: 0.6010 - val_MeanSquaredError: 0.1980 - val_accuracy: 0.7100 - val_loss: 0.6010\n",
      "Epoch 10/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 477ms/step - BinaryCrossentropy: 0.4649 - MeanSquaredError: 0.1520 - accuracy: 0.7805 - loss: 0.4649 - val_BinaryCrossentropy: 0.6056 - val_MeanSquaredError: 0.1992 - val_accuracy: 0.7060 - val_loss: 0.6056\n",
      "Epoch 11/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 476ms/step - BinaryCrossentropy: 0.4491 - MeanSquaredError: 0.1463 - accuracy: 0.7858 - loss: 0.4491 - val_BinaryCrossentropy: 0.5819 - val_MeanSquaredError: 0.1908 - val_accuracy: 0.7276 - val_loss: 0.5819\n",
      "Epoch 12/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m167s\u001B[0m 475ms/step - BinaryCrossentropy: 0.4300 - MeanSquaredError: 0.1393 - accuracy: 0.7996 - loss: 0.4300 - val_BinaryCrossentropy: 0.5852 - val_MeanSquaredError: 0.1908 - val_accuracy: 0.7220 - val_loss: 0.5852\n",
      "Epoch 13/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 477ms/step - BinaryCrossentropy: 0.4093 - MeanSquaredError: 0.1307 - accuracy: 0.8141 - loss: 0.4093 - val_BinaryCrossentropy: 0.5956 - val_MeanSquaredError: 0.1923 - val_accuracy: 0.7260 - val_loss: 0.5956\n",
      "Epoch 14/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 478ms/step - BinaryCrossentropy: 0.3924 - MeanSquaredError: 0.1248 - accuracy: 0.8232 - loss: 0.3924 - val_BinaryCrossentropy: 0.5773 - val_MeanSquaredError: 0.1879 - val_accuracy: 0.7228 - val_loss: 0.5773\n",
      "Epoch 15/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m169s\u001B[0m 479ms/step - BinaryCrossentropy: 0.3646 - MeanSquaredError: 0.1144 - accuracy: 0.8406 - loss: 0.3646 - val_BinaryCrossentropy: 0.5999 - val_MeanSquaredError: 0.1941 - val_accuracy: 0.7220 - val_loss: 0.5999\n",
      "Epoch 16/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 478ms/step - BinaryCrossentropy: 0.3595 - MeanSquaredError: 0.1124 - accuracy: 0.8445 - loss: 0.3595 - val_BinaryCrossentropy: 0.5986 - val_MeanSquaredError: 0.1931 - val_accuracy: 0.7168 - val_loss: 0.5986\n",
      "Epoch 17/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 476ms/step - BinaryCrossentropy: 0.3420 - MeanSquaredError: 0.1058 - accuracy: 0.8578 - loss: 0.3420 - val_BinaryCrossentropy: 0.5627 - val_MeanSquaredError: 0.1810 - val_accuracy: 0.7408 - val_loss: 0.5627\n",
      "Epoch 18/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m170s\u001B[0m 482ms/step - BinaryCrossentropy: 0.3238 - MeanSquaredError: 0.0988 - accuracy: 0.8662 - loss: 0.3238 - val_BinaryCrossentropy: 0.5848 - val_MeanSquaredError: 0.1865 - val_accuracy: 0.7364 - val_loss: 0.5848\n",
      "Epoch 19/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 478ms/step - BinaryCrossentropy: 0.3120 - MeanSquaredError: 0.0944 - accuracy: 0.8764 - loss: 0.3120 - val_BinaryCrossentropy: 0.5792 - val_MeanSquaredError: 0.1847 - val_accuracy: 0.7332 - val_loss: 0.5792\n",
      "Epoch 20/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 478ms/step - BinaryCrossentropy: 0.2990 - MeanSquaredError: 0.0899 - accuracy: 0.8809 - loss: 0.2990 - val_BinaryCrossentropy: 0.5563 - val_MeanSquaredError: 0.1765 - val_accuracy: 0.7508 - val_loss: 0.5563\n",
      "Epoch 21/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 478ms/step - BinaryCrossentropy: 0.2715 - MeanSquaredError: 0.0799 - accuracy: 0.8986 - loss: 0.2715 - val_BinaryCrossentropy: 0.5678 - val_MeanSquaredError: 0.1794 - val_accuracy: 0.7452 - val_loss: 0.5678\n",
      "Epoch 22/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m168s\u001B[0m 477ms/step - BinaryCrossentropy: 0.2705 - MeanSquaredError: 0.0793 - accuracy: 0.8997 - loss: 0.2705 - val_BinaryCrossentropy: 0.5643 - val_MeanSquaredError: 0.1779 - val_accuracy: 0.7484 - val_loss: 0.5643\n",
      "Epoch 23/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m175s\u001B[0m 497ms/step - BinaryCrossentropy: 0.2580 - MeanSquaredError: 0.0749 - accuracy: 0.9048 - loss: 0.2580 - val_BinaryCrossentropy: 0.5698 - val_MeanSquaredError: 0.1794 - val_accuracy: 0.7480 - val_loss: 0.5698\n",
      "Epoch 24/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m173s\u001B[0m 490ms/step - BinaryCrossentropy: 0.2420 - MeanSquaredError: 0.0691 - accuracy: 0.9165 - loss: 0.2420 - val_BinaryCrossentropy: 0.5718 - val_MeanSquaredError: 0.1788 - val_accuracy: 0.7408 - val_loss: 0.5718\n",
      "Epoch 25/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m179s\u001B[0m 507ms/step - BinaryCrossentropy: 0.2332 - MeanSquaredError: 0.0663 - accuracy: 0.9178 - loss: 0.2332 - val_BinaryCrossentropy: 0.5761 - val_MeanSquaredError: 0.1798 - val_accuracy: 0.7444 - val_loss: 0.5761\n",
      "Epoch 26/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m183s\u001B[0m 519ms/step - BinaryCrossentropy: 0.2274 - MeanSquaredError: 0.0640 - accuracy: 0.9230 - loss: 0.2274 - val_BinaryCrossentropy: 0.5658 - val_MeanSquaredError: 0.1752 - val_accuracy: 0.7584 - val_loss: 0.5658\n",
      "Epoch 27/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m182s\u001B[0m 517ms/step - BinaryCrossentropy: 0.2075 - MeanSquaredError: 0.0565 - accuracy: 0.9374 - loss: 0.2075 - val_BinaryCrossentropy: 0.5661 - val_MeanSquaredError: 0.1739 - val_accuracy: 0.7616 - val_loss: 0.5661\n",
      "Epoch 28/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m184s\u001B[0m 522ms/step - BinaryCrossentropy: 0.2037 - MeanSquaredError: 0.0558 - accuracy: 0.9365 - loss: 0.2037 - val_BinaryCrossentropy: 0.5750 - val_MeanSquaredError: 0.1761 - val_accuracy: 0.7520 - val_loss: 0.5750\n",
      "Epoch 29/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m178s\u001B[0m 506ms/step - BinaryCrossentropy: 0.2001 - MeanSquaredError: 0.0547 - accuracy: 0.9352 - loss: 0.2001 - val_BinaryCrossentropy: 0.5672 - val_MeanSquaredError: 0.1737 - val_accuracy: 0.7584 - val_loss: 0.5672\n",
      "Epoch 30/30\n",
      "\u001B[1m352/352\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m179s\u001B[0m 508ms/step - BinaryCrossentropy: 0.1816 - MeanSquaredError: 0.0479 - accuracy: 0.9485 - loss: 0.1816 - val_BinaryCrossentropy: 0.5674 - val_MeanSquaredError: 0.1739 - val_accuracy: 0.7572 - val_loss: 0.5674\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:01:09.781003Z",
     "start_time": "2024-12-02T11:01:05.014526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluating CNN model predictions on validation data\n",
    "\n",
    "#preds = np.asarray(preds).flatten()\n",
    "labels_flat = np.asarray(labels_valid).flatten()\n",
    "\n",
    "preds = catdog_model.predict(x_valid)\n",
    "preds = np.asarray([pred[0] for pred in preds])\n",
    "\n",
    "np.corrcoef(preds, labels_flat)"
   ],
   "id": "5997704ed27030a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m79/79\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.57567404],\n",
       "       [0.57567404, 1.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:01:10.579633Z",
     "start_time": "2024-12-02T11:01:09.807175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Saving model\n",
    "catdog_model.save('untuned_model.keras')"
   ],
   "id": "f55ed7f1c0879b8f",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fine-tuning model on big cats",
   "id": "138c438e3f6c5b54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:38:51.292429Z",
     "start_time": "2024-12-02T11:38:50.991003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading model to variable\n",
    "untuned_model = keras.models.load_model('untuned_model.keras')"
   ],
   "id": "d7257f79f44453b5",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:38:51.951436Z",
     "start_time": "2024-12-02T11:38:51.949132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in untuned_model.layers:\n",
    "    if isinstance(layer, layers.Conv2D):\n",
    "        layer.trainable = False"
   ],
   "id": "4a5382b8c197d53a",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:38:53.155795Z",
     "start_time": "2024-12-02T11:38:53.125381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove classification head\n",
    "conv_x = untuned_model.get_layer(\"flattened_features\").output\n",
    "\n",
    "# Add new dense layers for big cats\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='new_fc')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='bigcat_class')(conv_x)\n",
    "\n",
    "# Create new model\n",
    "bigcat_model = keras.Model(inputs=untuned_model.input, outputs=conv_outputs)"
   ],
   "id": "54c87d75cdc1926c",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:38:54.986014Z",
     "start_time": "2024-12-02T11:38:54.981678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=1e-6)  # Small learning rate for transfer learning\n",
    "bigcat_model.compile(optimizer=customAdam,\n",
    "                         loss=\"BinaryCrossentropy\",\n",
    "                         metrics=[\"BinaryCrossentropy\",\"MeanSquaredError\", \"accuracy\"])"
   ],
   "id": "851dfc5eb12416bf",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:42:37.014517Z",
     "start_time": "2024-12-02T11:38:56.192601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = bigcat_model.fit(x_tune,\n",
    "                               labels_tune,\n",
    "                               batch_size=64,\n",
    "                               shuffle=True,\n",
    "                               epochs=15,  # Start with fewer epochs\n",
    "                               validation_data=(x_valid_tune, labels_valid_tune))"
   ],
   "id": "6f65d2cd871b5583",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 215ms/step - BinaryCrossentropy: 2.8196 - MeanSquaredError: 0.3897 - accuracy: 0.5701 - loss: 2.8196 - val_BinaryCrossentropy: 1.5988 - val_MeanSquaredError: 0.2962 - val_accuracy: 0.6636 - val_loss: 1.5988\n",
      "Epoch 2/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 219ms/step - BinaryCrossentropy: 1.4057 - MeanSquaredError: 0.2758 - accuracy: 0.6672 - loss: 1.4057 - val_BinaryCrossentropy: 1.3368 - val_MeanSquaredError: 0.2611 - val_accuracy: 0.7000 - val_loss: 1.3368\n",
      "Epoch 3/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 212ms/step - BinaryCrossentropy: 1.1021 - MeanSquaredError: 0.2274 - accuracy: 0.7282 - loss: 1.1021 - val_BinaryCrossentropy: 1.1201 - val_MeanSquaredError: 0.2388 - val_accuracy: 0.7159 - val_loss: 1.1201\n",
      "Epoch 4/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 214ms/step - BinaryCrossentropy: 0.8754 - MeanSquaredError: 0.1948 - accuracy: 0.7569 - loss: 0.8754 - val_BinaryCrossentropy: 1.0149 - val_MeanSquaredError: 0.2244 - val_accuracy: 0.7295 - val_loss: 1.0149\n",
      "Epoch 5/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 214ms/step - BinaryCrossentropy: 0.7269 - MeanSquaredError: 0.1684 - accuracy: 0.7895 - loss: 0.7269 - val_BinaryCrossentropy: 0.9693 - val_MeanSquaredError: 0.2165 - val_accuracy: 0.7386 - val_loss: 0.9693\n",
      "Epoch 6/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 211ms/step - BinaryCrossentropy: 0.6251 - MeanSquaredError: 0.1490 - accuracy: 0.8121 - loss: 0.6251 - val_BinaryCrossentropy: 0.9523 - val_MeanSquaredError: 0.2196 - val_accuracy: 0.7318 - val_loss: 0.9523\n",
      "Epoch 7/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 211ms/step - BinaryCrossentropy: 0.5994 - MeanSquaredError: 0.1521 - accuracy: 0.8089 - loss: 0.5994 - val_BinaryCrossentropy: 0.8959 - val_MeanSquaredError: 0.2117 - val_accuracy: 0.7250 - val_loss: 0.8959\n",
      "Epoch 8/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 211ms/step - BinaryCrossentropy: 0.5094 - MeanSquaredError: 0.1337 - accuracy: 0.8276 - loss: 0.5094 - val_BinaryCrossentropy: 0.8469 - val_MeanSquaredError: 0.2034 - val_accuracy: 0.7409 - val_loss: 0.8469\n",
      "Epoch 9/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 212ms/step - BinaryCrossentropy: 0.4278 - MeanSquaredError: 0.1152 - accuracy: 0.8500 - loss: 0.4278 - val_BinaryCrossentropy: 0.8660 - val_MeanSquaredError: 0.2059 - val_accuracy: 0.7545 - val_loss: 0.8660\n",
      "Epoch 10/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 212ms/step - BinaryCrossentropy: 0.3762 - MeanSquaredError: 0.1056 - accuracy: 0.8576 - loss: 0.3762 - val_BinaryCrossentropy: 0.8224 - val_MeanSquaredError: 0.2002 - val_accuracy: 0.7386 - val_loss: 0.8224\n",
      "Epoch 11/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 211ms/step - BinaryCrossentropy: 0.3259 - MeanSquaredError: 0.0948 - accuracy: 0.8691 - loss: 0.3259 - val_BinaryCrossentropy: 0.7694 - val_MeanSquaredError: 0.1921 - val_accuracy: 0.7500 - val_loss: 0.7694\n",
      "Epoch 12/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 213ms/step - BinaryCrossentropy: 0.3434 - MeanSquaredError: 0.0967 - accuracy: 0.8726 - loss: 0.3434 - val_BinaryCrossentropy: 0.8030 - val_MeanSquaredError: 0.1967 - val_accuracy: 0.7455 - val_loss: 0.8030\n",
      "Epoch 13/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 212ms/step - BinaryCrossentropy: 0.3620 - MeanSquaredError: 0.0986 - accuracy: 0.8673 - loss: 0.3620 - val_BinaryCrossentropy: 0.7808 - val_MeanSquaredError: 0.1875 - val_accuracy: 0.7818 - val_loss: 0.7808\n",
      "Epoch 14/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 211ms/step - BinaryCrossentropy: 0.3042 - MeanSquaredError: 0.0884 - accuracy: 0.8797 - loss: 0.3042 - val_BinaryCrossentropy: 0.7396 - val_MeanSquaredError: 0.1779 - val_accuracy: 0.7750 - val_loss: 0.7396\n",
      "Epoch 15/15\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 213ms/step - BinaryCrossentropy: 0.2315 - MeanSquaredError: 0.0659 - accuracy: 0.9137 - loss: 0.2315 - val_BinaryCrossentropy: 0.7169 - val_MeanSquaredError: 0.1747 - val_accuracy: 0.7750 - val_loss: 0.7169\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:42:37.905801Z",
     "start_time": "2024-12-02T11:42:37.039473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluating finetuned model predictions on validation data\n",
    "labels_flat = np.asarray(labels_valid_tune).flatten()\n",
    "preds = bigcat_model.predict(x_valid_tune)\n",
    "preds = np.asarray([pred[0] for pred in preds])\n",
    "\n",
    "print(np.corrcoef(preds, labels_flat))"
   ],
   "id": "b1eb3cd6f2af7a2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step\n",
      "[[1.         0.60602215]\n",
      " [0.60602215 1.        ]]\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:42:37.910522Z",
     "start_time": "2024-12-02T11:42:37.907796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MSE for predictions\n",
    "# Closer to 0 is better\n",
    "print(mean_squared_error(labels_flat, preds))"
   ],
   "id": "2d911417d1643a3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17466860461105638\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:42:37.932777Z",
     "start_time": "2024-12-02T11:42:37.928734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Receiver Operating Characteristic and Area Under Curve\n",
    "# Closer to 1 is better\n",
    "print(roc_auc_score(labels_flat, preds))"
   ],
   "id": "e85c86bf07adecf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8585743801652892\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:42:38.510321Z",
     "start_time": "2024-12-02T11:42:37.951208Z"
    }
   },
   "cell_type": "code",
   "source": "bigcat_model.save(\"tuned_model.keras\")",
   "id": "6392a17e0da35281",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Optional for larger datasets",
   "id": "7bb6354574a77e18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:42:38.531505Z",
     "start_time": "2024-12-02T11:42:38.528609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in bigcat_model.layers:\n",
    "    if isinstance(layer, layers.Conv2D):\n",
    "        layer.trainable = True  # Unfreeze convolutional layers"
   ],
   "id": "cb3b88eea80be47a",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:45:28.073878Z",
     "start_time": "2024-12-02T11:42:38.549325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=1e-7)  # Even smaller learning rate\n",
    "bigcat_model.compile(optimizer=customAdam,\n",
    "                         loss=\"BinaryCrossentropy\",\n",
    "                         metrics=[\"BinaryCrossentropy\",\"MeanSquaredError\", \"accuracy\"])\n",
    "\n",
    "history_fine = bigcat_model.fit(x_tune,\n",
    "                                    labels_tune,\n",
    "                                    batch_size=64,\n",
    "                                    shuffle=True,\n",
    "                                    epochs=5,       # Fewer epochs\n",
    "                                    validation_data=(x_valid_tune, labels_valid_tune))"
   ],
   "id": "7b5ede7a699582ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 490ms/step - BinaryCrossentropy: 0.2006 - MeanSquaredError: 0.0558 - accuracy: 0.9254 - loss: 0.2006 - val_BinaryCrossentropy: 0.7143 - val_MeanSquaredError: 0.1747 - val_accuracy: 0.7773 - val_loss: 0.7143\n",
      "Epoch 2/5\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 491ms/step - BinaryCrossentropy: 0.1875 - MeanSquaredError: 0.0526 - accuracy: 0.9310 - loss: 0.1875 - val_BinaryCrossentropy: 0.7193 - val_MeanSquaredError: 0.1754 - val_accuracy: 0.7886 - val_loss: 0.7193\n",
      "Epoch 3/5\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 486ms/step - BinaryCrossentropy: 0.1892 - MeanSquaredError: 0.0529 - accuracy: 0.9314 - loss: 0.1892 - val_BinaryCrossentropy: 0.7064 - val_MeanSquaredError: 0.1738 - val_accuracy: 0.7727 - val_loss: 0.7064\n",
      "Epoch 4/5\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 490ms/step - BinaryCrossentropy: 0.1861 - MeanSquaredError: 0.0524 - accuracy: 0.9297 - loss: 0.1861 - val_BinaryCrossentropy: 0.7089 - val_MeanSquaredError: 0.1736 - val_accuracy: 0.7773 - val_loss: 0.7089\n",
      "Epoch 5/5\n",
      "\u001B[1m69/69\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 487ms/step - BinaryCrossentropy: 0.1812 - MeanSquaredError: 0.0513 - accuracy: 0.9317 - loss: 0.1812 - val_BinaryCrossentropy: 0.7131 - val_MeanSquaredError: 0.1739 - val_accuracy: 0.7886 - val_loss: 0.7131\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:45:28.986557Z",
     "start_time": "2024-12-02T11:45:28.112907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluating finetuned model predictions on validation data\n",
    "labels_flat = np.asarray(labels_valid_tune).flatten()\n",
    "preds = bigcat_model.predict(x_valid_tune)\n",
    "preds = np.asarray([pred[0] for pred in preds])\n",
    "\n",
    "print(np.corrcoef(preds, labels_flat))"
   ],
   "id": "23914d7c0218596",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 58ms/step\n",
      "[[1.        0.6089629]\n",
      " [0.6089629 1.       ]]\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:45:28.992553Z",
     "start_time": "2024-12-02T11:45:28.990056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MSE for predictions\n",
    "# Closer to 0 is better\n",
    "print(mean_squared_error(labels_flat, preds))"
   ],
   "id": "f16e3e204c3b898",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17388696923331834\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:45:29.082086Z",
     "start_time": "2024-12-02T11:45:29.078396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Receiver Operating Characteristic and Area Under Curve\n",
    "# Closer to 1 is better\n",
    "print(roc_auc_score(labels_flat, preds))"
   ],
   "id": "3a97d38c407076e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8604338842975207\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T11:45:29.859207Z",
     "start_time": "2024-12-02T11:45:29.157403Z"
    }
   },
   "cell_type": "code",
   "source": "bigcat_model.save(\"retuned_model.keras\")",
   "id": "1478488850e12b89",
   "outputs": [],
   "execution_count": 74
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
