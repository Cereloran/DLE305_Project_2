{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing libraries",
   "id": "a54d8ceace5470a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# need this to make numpy compatible with other libraries\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install numpy==1.25.0"
   ],
   "id": "d5abae1c53b745ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:49:43.410343Z",
     "start_time": "2024-11-29T23:49:39.941254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers"
   ],
   "id": "128c2e6f75f9cb93",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:49:47.859860Z",
     "start_time": "2024-11-29T23:49:47.856541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sizing Seaborn plots for screenshots\n",
    "sns.set_theme(rc={'figure.figsize':(4,3)})"
   ],
   "id": "137c9eb725d79aee",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing",
   "id": "92dc9decc5d984fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:49:52.799953Z",
     "start_time": "2024-11-29T23:49:52.797188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specifying final image size and resizing to that size\n",
    "IMG_SIZE = (94, 125)\n",
    "def pixels_from_path(file_path):\n",
    "    im = Image.open(file_path)\n",
    "\n",
    "    im = im.resize(IMG_SIZE)\n",
    "    np_im = np.array(im)\n",
    "    # Returns 3D array of RGB values for image\n",
    "    return np_im"
   ],
   "id": "3c87fafffcd5fd2a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:49:53.996034Z",
     "start_time": "2024-11-29T23:49:53.992396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Input relevant filepath before '/cat'\n",
    "cat_filepath = 'cat/*'\n",
    "dog_filepath = 'dog/*'\n",
    "tiger_filepath = 'tiger/*'\n",
    "lion_filepath = 'lion/*'"
   ],
   "id": "3d223d9db0129e42",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:50:14.371349Z",
     "start_time": "2024-11-29T23:49:54.938896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shape_counts = defaultdict(int)\n",
    "for i, cat in enumerate(glob.glob(cat_filepath)):\n",
    "    # Will print iteration no. if i+1 is a multiple of 500\n",
    "    if (i+1)%500==0:\n",
    "        print(i)\n",
    "    img_shape = pixels_from_path(cat).shape\n",
    "    shape_counts[str(img_shape)]= shape_counts[str(img_shape)]+ 1"
   ],
   "id": "420418a30617bb12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "999\n",
      "1499\n",
      "1999\n",
      "2499\n",
      "2999\n",
      "3499\n",
      "3999\n",
      "4499\n",
      "4999\n",
      "5499\n",
      "5999\n",
      "6499\n",
      "6999\n",
      "7499\n",
      "7999\n",
      "8499\n",
      "8999\n",
      "9499\n",
      "9999\n",
      "10499\n",
      "10999\n",
      "11499\n",
      "11999\n",
      "12499\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:50:14.379465Z",
     "start_time": "2024-11-29T23:50:14.376336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shape_items = list(shape_counts.items())\n",
    "shape_items.sort(key = lambda x: x[1])\n",
    "shape_items.reverse()"
   ],
   "id": "5b69870835ab88cc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:50:19.536340Z",
     "start_time": "2024-11-29T23:50:19.533498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 10% of the data will be used for validation\n",
    "validation_size = 0.1\n",
    "img_size = IMG_SIZE # resize images to be 0.25x most common shape (374x500)\n",
    "num_channels = 3 # RGB\n",
    "sample_size = 25000 # Using all training data for the sample size"
   ],
   "id": "befa77817e53f517",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:50:20.913750Z",
     "start_time": "2024-11-29T23:50:20.877186Z"
    }
   },
   "cell_type": "code",
   "source": "len(glob.glob(cat_filepath))",
   "id": "d4f575950c1194d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:50:21.707182Z",
     "start_time": "2024-11-29T23:50:21.669Z"
    }
   },
   "cell_type": "code",
   "source": "pixels_from_path(glob.glob(cat_filepath)[5]).shape",
   "id": "debf07bfdd96c957",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 94, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T00:28:17.250447Z",
     "start_time": "2024-11-30T00:28:17.246186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training size\n",
    "SAMPLE_SIZE = 11250\n",
    "SAMPLE_SIZE_TUNING = 400    # different due to different dataset size\n",
    "\n",
    "# Validation size\n",
    "valid_size = 1250\n",
    "valid_size_tuning = 40      # different due to different dataset size"
   ],
   "id": "ed5c743ce4384909",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T00:28:52.418947Z",
     "start_time": "2024-11-30T00:28:18.914692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"loading training cat images...\")\n",
    "cat_train_set = np.asarray([pixels_from_path(cat) for cat in glob.glob(cat_filepath)[:SAMPLE_SIZE]])\n",
    "print(\"loading training dog images...\")\n",
    "dog_train_set = np.asarray([pixels_from_path(dog) for dog in glob.glob(dog_filepath)[:SAMPLE_SIZE]])\n",
    "print(\"loading training tiger images...\")\n",
    "tiger_train_set = np.asarray([pixels_from_path(tiger) for tiger in glob.glob(tiger_filepath)[:SAMPLE_SIZE_TUNING]])\n",
    "print(\"loading training lion images...\")\n",
    "lion_train_set = np.asarray([pixels_from_path(lion) for lion in glob.glob(lion_filepath)[:SAMPLE_SIZE_TUNING]])"
   ],
   "id": "9b1611f1653f0148",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training cat images...\n",
      "loading training dog images...\n",
      "loading training tiger images...\n",
      "loading training lion images...\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"loading validation cat images...\")\n",
    "cat_valid_set = np.asarray([pixels_from_path(cat) for cat in glob.glob(cat_filepath)[-valid_size:]])\n",
    "print(\"loading validation dog images...\")\n",
    "dog_valid_set = np.asarray([pixels_from_path(dog) for dog in glob.glob(dog_filepath)[-valid_size:]])\n",
    "print(\"loading training tiger images...\")\n",
    "tiger_valid_set = np.asarray([pixels_from_path(tiger) for tiger in glob.glob(tiger_filepath)[-valid_size_tuning:]])\n",
    "print(\"loading training lion images...\")\n",
    "lion_valid_set = np.asarray([pixels_from_path(lion) for lion in glob.glob(lion_filepath)[-valid_size_tuning:]])"
   ],
   "id": "8f71213b747f6d26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_train = np.concatenate([cat_train_set, dog_train_set])\n",
    "# Applying labels based on sample size because data are currently ordered by class\n",
    "labels_train = np.asarray([1 for _ in range(SAMPLE_SIZE)]+[0 for _ in range(SAMPLE_SIZE)])"
   ],
   "id": "9780d0b2ddbe8bb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_tune = np.concatenate([tiger_train_set, lion_train_set])\n",
    "# Applying labels based on sample size because data are currently ordered by class\n",
    "labels_tune = np.asarray([1 for _ in range(SAMPLE_SIZE_TUNING)]+[0 for _ in range(SAMPLE_SIZE_TUNING)])"
   ],
   "id": "34ec9f3d6cf7c260"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_valid = np.concatenate([cat_valid_set, dog_valid_set])\n",
    "# Applying labels based on validation sample size because data are currently ordered by class\n",
    "labels_valid = np.asarray([1 for _ in range(valid_size)]+[0 for _ in range(valid_size)])"
   ],
   "id": "95d6d6f8258fe360"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_valid_tune = np.concatenate([tiger_train_set, lion_train_set])\n",
    "# Applying labels based on validation sample size because data are currently ordered by class\n",
    "labels_valid_tune = np.asarray([1 for _ in range(valid_size_tuning)]+[0 for _ in range(valid_size_tuning)])"
   ],
   "id": "dac285915e029c08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reshape labels to match output\n",
    "labels_train = labels_train.reshape(-1,1)\n",
    "labels_valid = labels_valid.reshape(-1,1)"
   ],
   "id": "1e8536851215ee2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x_train.shape",
   "id": "a7c18f2725c8a716"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "labels_train.shape",
   "id": "aa59628b4cdaa67c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "labels_train[:10]  # Checking values to ensure they're not None",
   "id": "fd5d1c2a8e2552"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "labels_train[22490:]  # Checking values to ensure they're not None",
   "id": "e5bdad8ff172e1a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN from A2",
   "id": "a7d75a240e9be6bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fully connected layer neuron number\n",
    "fc_layer_size = 256\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "# Convolution parameters\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "catdog_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)"
   ],
   "id": "10e91ab65cf7b3b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=1e-6)\n",
    "catdog_model.compile(optimizer=customAdam,  # Optimizer\n",
    "                        # Loss function to minimize\n",
    "                        loss=\"BinaryCrossentropy\",\n",
    "                        # List of metrics to monitor\n",
    "                        metrics=[\"BinaryCrossentropy\",\"MeanSquaredError\"])"
   ],
   "id": "61a85bd2a6796445"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = catdog_model.fit(x_train,\n",
    "                              labels_train,\n",
    "                              batch_size=64,\n",
    "                              shuffle = True,\n",
    "                              epochs=30,\n",
    "                              validation_data=(x_valid, labels_valid))"
   ],
   "id": "e2c3bdea567bb89a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluating CNN model predictions on validation data\n",
    "\n",
    "preds = np.asarray(preds).flatten()\n",
    "labels_flat = np.asarray(labels_valid).flatten()\n",
    "\n",
    "preds = catdog_model.predict(x_valid)\n",
    "preds = np.asarray([pred[0] for pred in preds])\n",
    "\n",
    "np.corrcoef(preds, labels_flat)"
   ],
   "id": "cde942ee1e136452"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Saving model\n",
    "catdog_model.save('untuned_model.keras')\n",
    "\n",
    "# Loading model to variable\n",
    "untuned_model = keras.models.load_model('untuned_model.keras')"
   ],
   "id": "127d197cc05e2962"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fine-tuning model on big cats",
   "id": "138c438e3f6c5b54"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
