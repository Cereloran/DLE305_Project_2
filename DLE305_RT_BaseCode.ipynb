{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing libraries",
   "id": "a54d8ceace5470a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers"
   ],
   "id": "6d41e5de45384b4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sizing Seaborn plots for screenshots\n",
    "sns.set_theme(rc={'figure.figsize':(4,3)})"
   ],
   "id": "aa08dcb21de820a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing",
   "id": "92dc9decc5d984fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:49:52.799953Z",
     "start_time": "2024-11-29T23:49:52.797188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specifying final image size and resizing to that size\n",
    "IMG_SIZE = (94, 125)\n",
    "def pixels_from_path(file_path):\n",
    "    im = Image.open(file_path)\n",
    "\n",
    "    im = im.resize(IMG_SIZE)\n",
    "    np_im = np.array(im)\n",
    "    # Returns 3D array of RGB values for image\n",
    "    return np_im"
   ],
   "id": "3c87fafffcd5fd2a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:49:53.996034Z",
     "start_time": "2024-11-29T23:49:53.992396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Input relevant filepath before '/cat'\n",
    "cat_filepath = 'cat/*'\n",
    "dog_filepath = 'dog/*'\n",
    "tiger_filepath = 'tiger/*'\n",
    "lion_filepath = 'lion/*'"
   ],
   "id": "3d223d9db0129e42",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:50:14.371349Z",
     "start_time": "2024-11-29T23:49:54.938896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shape_counts = defaultdict(int)\n",
    "for i, cat in enumerate(glob.glob(cat_filepath)):\n",
    "    # Will print iteration no. if i+1 is a multiple of 500\n",
    "    if (i+1)%500==0:\n",
    "        print(i)\n",
    "    img_shape = pixels_from_path(cat).shape\n",
    "    shape_counts[str(img_shape)]= shape_counts[str(img_shape)]+ 1"
   ],
   "id": "420418a30617bb12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n",
      "999\n",
      "1499\n",
      "1999\n",
      "2499\n",
      "2999\n",
      "3499\n",
      "3999\n",
      "4499\n",
      "4999\n",
      "5499\n",
      "5999\n",
      "6499\n",
      "6999\n",
      "7499\n",
      "7999\n",
      "8499\n",
      "8999\n",
      "9499\n",
      "9999\n",
      "10499\n",
      "10999\n",
      "11499\n",
      "11999\n",
      "12499\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:50:14.379465Z",
     "start_time": "2024-11-29T23:50:14.376336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shape_items = list(shape_counts.items())\n",
    "shape_items.sort(key = lambda x: x[1])\n",
    "shape_items.reverse()"
   ],
   "id": "5b69870835ab88cc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:50:19.536340Z",
     "start_time": "2024-11-29T23:50:19.533498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 10% of the data will be used for validation\n",
    "validation_size = 0.1\n",
    "img_size = IMG_SIZE # resize images to be 0.25x most common shape (374x500)\n",
    "num_channels = 3 # RGB\n",
    "sample_size = 25000 # Using all training data for the sample size"
   ],
   "id": "befa77817e53f517",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:50:20.913750Z",
     "start_time": "2024-11-29T23:50:20.877186Z"
    }
   },
   "cell_type": "code",
   "source": "len(glob.glob(cat_filepath))",
   "id": "d4f575950c1194d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T23:50:21.707182Z",
     "start_time": "2024-11-29T23:50:21.669Z"
    }
   },
   "cell_type": "code",
   "source": "pixels_from_path(glob.glob(cat_filepath)[5]).shape",
   "id": "debf07bfdd96c957",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 94, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Training size\n",
    "SAMPLE_SIZE = 11250\n",
    "SAMPLE_SIZE_TUNING = 200    # different due to different dataset size\n",
    "\n",
    "# Validation size\n",
    "valid_size = 1250\n",
    "valid_size_tuning = 20      # different due to different dataset size"
   ],
   "id": "5474334af963daeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"loading training cat images...\")\n",
    "cat_train_set = np.asarray([pixels_from_path(cat) for cat in glob.glob(cat_filepath)[:SAMPLE_SIZE]])\n",
    "print(\"loading training dog images...\")\n",
    "dog_train_set = np.asarray([pixels_from_path(dog) for dog in glob.glob(dog_filepath)[:SAMPLE_SIZE]])\n",
    "print(\"loading training tiger images...\")\n",
    "tiger_train_set_rgba = np.asarray([pixels_from_path(tiger) for tiger in glob.glob(tiger_filepath)[:SAMPLE_SIZE_TUNING]])\n",
    "tiger_train_set = tiger_train_set_rgba[..., :3]     # rgb only\n",
    "print(\"loading training lion images...\")\n",
    "lion_train_set_rgba = np.asarray([pixels_from_path(lion) for lion in glob.glob(lion_filepath)[:SAMPLE_SIZE_TUNING]])\n",
    "lion_train_set = lion_train_set_rgba[..., :3]       # rgb only"
   ],
   "id": "fd1b6b9f23a9bc88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"loading validation cat images...\")\n",
    "cat_valid_set = np.asarray([pixels_from_path(cat) for cat in glob.glob(cat_filepath)[-valid_size:]])\n",
    "print(\"loading validation dog images...\")\n",
    "dog_valid_set = np.asarray([pixels_from_path(dog) for dog in glob.glob(dog_filepath)[-valid_size:]])\n",
    "print(\"loading training tiger images...\")\n",
    "tiger_valid_set_rgba = np.asarray([pixels_from_path(tiger) for tiger in glob.glob(tiger_filepath)[-valid_size_tuning:]])\n",
    "tiger_valid_set = tiger_valid_set_rgba[..., :3]     # rgb only\n",
    "print(\"loading training lion images...\")\n",
    "lion_valid_set_rgba = np.asarray([pixels_from_path(lion) for lion in glob.glob(lion_filepath)[-valid_size_tuning:]])\n",
    "lion_valid_set = lion_valid_set_rgba[..., :3]       # rgb only"
   ],
   "id": "76471bccf4621b6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_train = np.concatenate([cat_train_set, dog_train_set])\n",
    "# Applying labels based on sample size because data are currently ordered by class\n",
    "labels_train = np.asarray([1 for _ in range(SAMPLE_SIZE)]+[0 for _ in range(SAMPLE_SIZE)])"
   ],
   "id": "cd74290b5d627755"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_tune = np.concatenate([tiger_train_set, lion_train_set])\n",
    "# Applying labels based on sample size because data are currently ordered by class\n",
    "labels_tune = np.asarray([1 for _ in range(SAMPLE_SIZE_TUNING)]+[0 for _ in range(SAMPLE_SIZE_TUNING)])"
   ],
   "id": "2176a0b4a3a2a514"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_valid = np.concatenate([cat_valid_set, dog_valid_set])\n",
    "# Applying labels based on validation sample size because data are currently ordered by class\n",
    "labels_valid = np.asarray([1 for _ in range(valid_size)]+[0 for _ in range(valid_size)])"
   ],
   "id": "95d6d6f8258fe360"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_valid_tune = np.concatenate([tiger_valid_set, lion_valid_set])\n",
    "# Applying labels based on validation sample size because data are currently ordered by class\n",
    "labels_valid_tune = np.asarray([1 for _ in range(valid_size_tuning)]+[0 for _ in range(valid_size_tuning)])"
   ],
   "id": "12bab1b0f03f406d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reshape labels to match output\n",
    "labels_train = labels_train.reshape(-1,1)\n",
    "labels_valid = labels_valid.reshape(-1,1)"
   ],
   "id": "8746156b1309df95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "labels_tune = labels_tune.reshape(-1,1)\n",
    "labels_valid_tune = labels_valid_tune.reshape(-1,1)"
   ],
   "id": "738d5da27384d4f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x_train.shape",
   "id": "a669bfba765875fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "labels_train.shape",
   "id": "e761935e41582d0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "labels_train[:10]  # Checking values to ensure they're not None",
   "id": "fd5d1c2a8e2552"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "labels_train[22490:]  # Checking values to ensure they're not None",
   "id": "29a0ebd2a5e956fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fully connected layer neuron number\n",
    "fc_layer_size = 256"
   ],
   "id": "94a59741538511bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN from A2",
   "id": "a7d75a240e9be6bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convolution parameters\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "catdog_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)"
   ],
   "id": "223c6a634c4fa382"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=1e-6)\n",
    "catdog_model.compile(optimizer=customAdam,  # Optimizer\n",
    "                        # Loss function to minimize\n",
    "                        loss=\"BinaryCrossentropy\",\n",
    "                        # List of metrics to monitor\n",
    "                        metrics=[\"BinaryCrossentropy\",\"MeanSquaredError\", \"accuracy\"])"
   ],
   "id": "63f96b1617eda2ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = catdog_model.fit(x_train,\n",
    "                              labels_train,\n",
    "                              batch_size=64,\n",
    "                              shuffle = True,\n",
    "                              epochs=30,\n",
    "                              validation_data=(x_valid, labels_valid))"
   ],
   "id": "c0eeba8482494ca2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluating CNN model predictions on validation data\n",
    "\n",
    "preds = np.asarray(preds).flatten()\n",
    "labels_flat = np.asarray(labels_valid).flatten()\n",
    "\n",
    "preds = catdog_model.predict(x_valid)\n",
    "preds = np.asarray([pred[0] for pred in preds])\n",
    "\n",
    "np.corrcoef(preds, labels_flat)"
   ],
   "id": "5997704ed27030a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Saving model\n",
    "catdog_model.save('untuned_model.keras')"
   ],
   "id": "f55ed7f1c0879b8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fine-tuning model on big cats",
   "id": "138c438e3f6c5b54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Loading model to variable\n",
    "untuned_model = keras.models.load_model('untuned_model.keras')"
   ],
   "id": "d7257f79f44453b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for layer in untuned_model.layers:\n",
    "    if isinstance(layer, layers.Conv2D):\n",
    "        layer.trainable = False"
   ],
   "id": "4a5382b8c197d53a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Remove the classification head\n",
    "conv_x = catdog_model.get_layer(\"flattened_features\").output\n",
    "\n",
    "# Add new dense layers for big cats\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='new_fc1')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='new_class')(conv_x)\n",
    "\n",
    "# Create the new model\n",
    "lion_tiger_model = keras.Model(inputs=catdog_model.input, outputs=conv_outputs)"
   ],
   "id": "54c87d75cdc1926c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=1e-5)  # Smaller learning rate for transfer learning\n",
    "lion_tiger_model.compile(optimizer=customAdam,\n",
    "                         loss=\"BinaryCrossentropy\",\n",
    "                         metrics=[\"accuracy\"])"
   ],
   "id": "851dfc5eb12416bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "history = lion_tiger_model.fit(x_train_lion_tiger,\n",
    "                               labels_train_lion_tiger,\n",
    "                               batch_size=64,\n",
    "                               shuffle=True,\n",
    "                               epochs=10,  # Start with fewer epochs\n",
    "                               validation_data=(x_valid_lion_tiger, labels_valid_lion_tiger))"
   ],
   "id": "6f65d2cd871b5583"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for layer in lion_tiger_model.layers:\n",
    "    if isinstance(layer, layers.Conv2D):\n",
    "        layer.trainable = True  # Unfreeze the convolutional layers"
   ],
   "id": "cb3b88eea80be47a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=1e-6)  # Even smaller learning rate\n",
    "lion_tiger_model.compile(optimizer=customAdam,\n",
    "                         loss=\"BinaryCrossentropy\",\n",
    "                         metrics=[\"accuracy\"])\n",
    "\n",
    "history_fine = lion_tiger_model.fit(x_train_lion_tiger,\n",
    "                                    labels_train_lion_tiger,\n",
    "                                    batch_size=64,\n",
    "                                    shuffle=True,\n",
    "                                    epochs=5,\n",
    "                                    validation_data=(x_valid_lion_tiger, labels_valid_lion_tiger))"
   ],
   "id": "7b5ede7a699582ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluating CNN model predictions on validation data\n",
    "labels_flat = np.asarray(labels_valid_tune).flatten()\n",
    "preds = bigcat_model.predict(x_valid_tune)\n",
    "preds = np.asarray([pred[0] for pred in preds])\n",
    "\n",
    "print(np.corrcoef(preds, labels_flat))"
   ],
   "id": "23914d7c0218596"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_loss, test_acc = lion_tiger_model.evaluate(x_test_lion_tiger, labels_test_lion_tiger)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ],
   "id": "2420c8ef78d5059a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
